---
title: "Centering Treatments"
author: "Art Eschenlauer"
date: "11/16/2019"
output:
  pdf_document:
    highlight: null
    number_sections: no
    toc: no
    toc_depth: 4
  html_document:
    df_print: paged
    toc: no
    toc_depth: '4'
  knitr:::html_vignette:
    fig_caption: yes
    toc: no
    toc_depth: 4
subtitle: Advanced function for 'W4M Data Subset'
vignette: |
  %\VignetteIndexEntry{Centering Treatments}
  \usepackage[utf8]{inputenc}
  \usepackage[all]{nowidow}
  \widowpenalty10000
  \clubpenalty10000
  %\VignetteEngine{knitr::rmarkdown}
# build vignette with rmarkdown::render("vignettes/centering-enhancement.Rmd", "all")
---

# Summary

An extension to convert a data matrix for a replicated design to a data matrix having one column per treatment.   

## Motivation

W4M does not have tools to contrast treaments *per se*.  Sample metadata annotations can indicate replicates of a common treatment, but predictive tools like Heat Map (i.e., hierarchical clustering) and Multivariate (running as PLS-DA) can predict multiple predicted treatments for samples from the same treatment.  This confounds examination of relationships among the treatments themselves.

This example collapses a data matrix having one column per sample to a data matrix having one column per treatment.  Each column is the "center" for the respective set of replicates for that treatment.  Normally distributed data may be analayzed using mean and standard deviation respectively for assessment of the center and the spread; data with unknown distribution, with median and the median absolute deviation.

The resulting treatment metadata include the following column:

- `trt`, the name of the treatment (i.e., the content of a specified column from `sampleMetadata`)
- `n`, the number of replicates for the treatment
- `d_dot` ($D^{\circ}$ or $D^{\bullet}$), which indicates the ratio of the spread of the replicates for the treatment to the spread between the treatments (analogous to D--ratio).

## Normally distributed data

For an example with normally distributed data, for each of $m$ treatments $i$ and each of $n_i$ replicates $p$ for each feature $j$:

$$ \text{center}_{{treatment_i},{intensity_j}} = mean(intensity_{i,j,p} \; \forall p \in [1,n_i]) $$ 

$$ \text{distance}_{treatment_i} = \sqrt{\sum_{k=1}^j \Big(stdev(intensity_{i,k,p} \; \forall p \in [1,n_i])\Big)^2} $$
$$ \text{center}_{overall,{intensity_j}} = mean(\text{center}_{{treatment_i},{intensity_j}} \; \forall i \in [1,m]) $$ 
$$ \text{distance}_{overall} = \sqrt{\sum_{k=1}^m \Big(stdev(\text{center}_{{treatment_i},{intensity_k}})\Big)^2} $$
$$ \text{$D^{\circ}$}_{treatment_i} = \frac{\text{distance}_{treatment_i}}{\text{distance}_{overall}}$$

## Unkown distribution

For an example with data having an unknown distribution, for each of $m$ treatments $i$ and each of $n_i$ replicates $p$ for each feature $j$:

$$ \text{center}_{{treatment_i},{intensity_j}} = median(intensity_{i,j,p} \; \forall p \in [1,n_i]) $$ 

$$ \text{distance}_{treatment_i} = \sqrt{\sum_{k=1}^j \Big(mad(intensity_{i,k,p} \; \forall p \in [1,n_i])\Big)^2} $$
$$ \text{center}_{overall,{intensity_j}} = median(\text{center}_{{treatment_i},{intensity_j}} \; \forall i \in [1,m]) $$ 
$$ \text{distance}_{overall} = \sqrt{\sum_{k=1}^m \Big(mad(\text{center}_{{treatment_i},{intensity_k}})\Big)^2} $$
$$ \text{$D^{\bullet}$}_{treatment_i} = \frac{\text{distance}_{treatment_i}}{\text{distance}_{overall}}$$

## Most representative sample for each treatment

In summary, compute the center for each treatment, then choose the sample closest to the center.

For each treatment $i$:

First compute the center 
$$\vec{c}_i = \text{center}_{{treatment_i},{intensity_j}} \forall j$$
as appropriate for the distribution of the data.

Next, compute the residual each sample $k$
$$\vec{{\text{residual}_{i_k}}} = \vec{x}_{i,k}-\vec{c}_{i,k})$$

Next, create the residual matrix having a column for the residual of each sample $k$ for treatment $i$
$${\textbf{residual}_{i}}$$

Next (but see alternative below), compute $S_i$, the covariance matrix of $\textbf{residual}_i$
$$S_i = ({\textbf{residual}_{i}})^T ({\textbf{residual}_{i}})$$

Next, compute the Mahalanobis distance from the location of each sample $k$
$$\vec{x}_{i,k}$$
to the center for the corresponding treatment, $\vec{c}_i$, as
$$D_M(\vec{x}_{i,k},\vec{\text{c}}_i)=\sqrt{(\vec{\text{residual}_{i_k}})^T {S_i}^{-1} (\vec{\text{residual}_{i_k}})}$$
Rather than computing $S_i$ for each sample, a (possibly better) alternative is to compute an overall, robust $S$ as described below and compute $D_M$ as
$$D_M(\vec{x}_{i,k},\vec{\text{c}}_i)=\sqrt{(\vec{\text{residual}_{i_k}})^T S^{-1} (\vec{\text{residual}_{i_k}})}$$

Next, choose the sample with the lowest $D_M$ as the most representative sample for the treatment.
$$\vec{c}_i = \text{center}_{\text{treatment}_i,\text{intensity}_j}$$

Next, recompute the residual each sample $k$
$$\vec{{\text{residual}_{i_k}}} = \vec{x}_{i,k}-\vec{c}_{i,k})$$

Next, recreate the residual matrix having a column for the residual of each sample $k$ for treatment $i$
$${\textbf{residual}_{i}}$$

Recompute the Mahalanobis distance for treatement $i$
$$D_M(\vec{x}_{i,k},\vec{\text{c}}_i)=\sqrt{(\vec{\text{residual}_{i_k}})^T S^{-1} (\vec{\text{residual}_{i_k}})}$$

For all $m$ treatments $i$, compute the center
$$ \vec{c} = \text{center}_{overall,{intensity_j}} = mean({\vec{c}_i,intensity_j} \; \forall i \in [1,m]) $$ 

Next, compute the residual each treatment $i$
$$\vec{{\text{residual}_{i}}} = \vec{x}_{i}-\vec{c}$$

Next, create the residual matrix having a column for the residual of each treatment $i$
$$\textbf{residual}$$

Next, compute the overall Mahalanobis distance
$$D_{M,\text{overall}} = \sqrt{(\textbf{residual})^T S^{-1} (\textbf{residual})}$$

Finally, for each treatment $i$ compute
$$ \text{$D^{\bullet}$}_{treatment_i} = \frac{\text{distance}_{treatment_i}}{\text{distance}_{overall}}$$

### Alternative estimation of covariance

As an alternative to computing $S_i$ for each treatment, it may be better to produce a robust estimate of the overall $S$ using `MASS::cov.mcd`.  This may be computationally more intensive but more robust.  It also does not necessitate computing the corresponding residual.

I imagine (as a compromise) that a sampling strategy (randomly picking samples) might make this faster.  (To determine the number of samples required, you may want to try increasing the number of samples from 20 or so until the the point of diminishing returns is reached).

## Options for output

- `center` - replace all replicates of a treatment with the center for the treatment.
- `append` - append the treatment centers to the samples.  Set `n` and `D_dot` for samples to `NA`.  This might be useful to calculate the distance between samples and (their own or other) treatment centers.
- `nearest` - replace all replicates with the replicate nearest to its treatment center.
- `note` - do not replace samples.  Set `n` and `D_dot` to `NA` for all replicates for a treatment except the replicate nearest to its treatment center. 

## Confidence Interval

Note that the Kibria (2006) evaluates the `median t` confidence interval for the *mean* of an assymetric distribution, defined as:

$$ \bar{x} \pm t_{\frac{\alpha}{2},n-1} \frac{\tilde{s}_1}{\sqrt{n}} \; \Bigg| \; \tilde{s}_1 = \sqrt{\frac{1}{n-1} \sum_{i=1}^n (x_i - \tilde{x})^2}, \tilde{x} = \text{sample median}$$

Presumably, the confidence interval for the *median* would be centered on the sample median:

$$ {\bf\tilde{x}} \pm t_{\frac{\alpha}{2},n-1} \frac{\tilde{s}_1}{\sqrt{n}} \; \Bigg| \; \tilde{s}_1 = \sqrt{\frac{1}{n-1} \sum_{i=1}^n (x_i - \tilde{x})^2}, \tilde{x} = \text{sample median}$$

## References

Kibria, B. M. Golam (2006) **Modified confidence intervals for the mean of the Asymmetric distribution.* Pakistan Journal of Statistics. **22**(2): 109-120.
